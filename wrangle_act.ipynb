{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "by Alina Bolat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import requests\n",
    "import tweepy\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather\n",
    "Gathering process consisted of following parts:  \n",
    "1. `twitter_archive_enhanced.csv` was avalable for manual download.\n",
    "2. `image_predictions.tsv` was avalable through a link for programmatic download from the Udacity Servers.\n",
    "3. `tweet_json.txt`\n",
    "***\n",
    "### Twitter Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      "tweet_id                      2356 non-null int64\n",
      "in_reply_to_status_id         78 non-null float64\n",
      "in_reply_to_user_id           78 non-null float64\n",
      "timestamp                     2356 non-null object\n",
      "source                        2356 non-null object\n",
      "text                          2356 non-null object\n",
      "retweeted_status_id           181 non-null float64\n",
      "retweeted_status_user_id      181 non-null float64\n",
      "retweeted_status_timestamp    181 non-null object\n",
      "expanded_urls                 2297 non-null object\n",
      "rating_numerator              2356 non-null int64\n",
      "rating_denominator            2356 non-null int64\n",
      "name                          2356 non-null object\n",
      "doggo                         2356 non-null object\n",
      "floofer                       2356 non-null object\n",
      "pupper                        2356 non-null object\n",
      "puppo                         2356 non-null object\n",
      "dtypes: float64(4), int64(3), object(10)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Import the csv file and store it in a dataframe\n",
    "twitter_archive = pd.read_csv('twitter-archive-enhanced.csv', encoding = 'utf-8')\n",
    "# Check the outcome\n",
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Twitter archive** is a dataframe with 17 Columns and 2355 observations.\n",
    "***\n",
    "### Image Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2075 entries, 0 to 2074\n",
      "Data columns (total 12 columns):\n",
      "tweet_id    2075 non-null int64\n",
      "jpg_url     2075 non-null object\n",
      "img_num     2075 non-null int64\n",
      "p1          2075 non-null object\n",
      "p1_conf     2075 non-null float64\n",
      "p1_dog      2075 non-null bool\n",
      "p2          2075 non-null object\n",
      "p2_conf     2075 non-null float64\n",
      "p2_dog      2075 non-null bool\n",
      "p3          2075 non-null object\n",
      "p3_conf     2075 non-null float64\n",
      "p3_dog      2075 non-null bool\n",
      "dtypes: bool(3), float64(3), int64(2), object(4)\n",
      "memory usage: 152.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Using Requests library download a file\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url)\n",
    "# Save the download file\n",
    "with open(url.split('/')[-1], mode = 'wb') as outfile:\n",
    "    outfile.write(response.content)\n",
    "\n",
    "# Import the csv file and store it in a dataframe\n",
    "image_predictions = pd.read_csv('image-predictions.tsv', sep = '\\t', encoding = 'utf-8')\n",
    "# Check the result\n",
    "image_predictions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image Predictions** datafram consists of 12 columns and 2075 observations.\n",
    "***\n",
    "### Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweeter API Authorisation - TO BE REMOVED IN THE FINAL SUBMISSION\n",
    "\n",
    "consumer_key = 'YjbtrwGkSX3mLWCpY7UHR3xmz'\n",
    "consumer_secret = 'WjCAuv9cjv6vv3WF5g6DUeMIozQZ75I2hyMkAIp4YhI3nKDbwc'\n",
    "access_token = '945286537952014337-CUSJNKbsfNJIqbPJcg4ZdRyoV28nM1T'\n",
    "access_secret = 'uNtHfM4krHIveRwdrYkErGG8WnZzxafpA3cdtIJuaw31G'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, \n",
    "                 parser = tweepy.parsers.JSONParser(), # Parse the result to Json Object\n",
    "                 wait_on_rate_limit = True, # Automatically wait for rate limits to replenish\n",
    "                 wait_on_rate_limit_notify = True) # Print a notification when Tweepy is waiting for rate limits to replenish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888202515573088257 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "873697596434513921 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "869988702071779329 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "866816280283807744 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "861769973181624320 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "845459076796616705 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "842892208864923648 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "837012587749474308 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "827228250799742977 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "802247111496568832 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "775096608509886464 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 572\n",
      "Rate limit reached. Sleeping for: 602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997.1832611560822\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Liste where we will store the dictionaries of our result\n",
    "df_list = []\n",
    "# Liste frame where we will store the tweet_id of the errors\n",
    "error_list = []\n",
    "\n",
    "# Calculate the time of excution\n",
    "start = time.time()\n",
    "\n",
    "# Get the tweet object for all the teweets in archive dataframe \n",
    "for tweet_id in twitter_archive['tweet_id']:\n",
    "    try:\n",
    "        page = api.get_status(tweet_id, tweet_mode = 'extended')\n",
    "        # Print one page to look at the structure of the returned file\n",
    "        # and the names of attributes\n",
    "        # print(json.dumps(page, indent = 4))\n",
    "        #break\n",
    "        \n",
    "        favorites = page['favorite_count'] # How many favorites the tweet had\n",
    "        retweets = page['retweet_count'] # Count of the retweet\n",
    "        user_followers = page['user']['followers_count'] # How many followers the user had\n",
    "        user_favourites = page['user']['favourites_count'] # How many favorites the user had\n",
    "        date_time = page['created_at'] # The date and time of the creation\n",
    "        \n",
    "        df_list.append({'tweet_id': int(tweet_id),\n",
    "                        'favorites': int(favorites),\n",
    "                        'retweets': int(retweets),\n",
    "                        'user_followers': int(user_followers),\n",
    "                        'user_favourites': int(user_favourites),\n",
    "                        'date_time': pd.to_datetime(date_time)})\n",
    "    \n",
    "    # Catch the exceptions of the TweepError\n",
    "    except Exception as e:\n",
    "        print(str(tweet_id)+ \" _ \" + str(e))\n",
    "        error_list.append(tweet_id)\n",
    "\n",
    "# Calculate the time of excution\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "# 888202515573088257 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
    "# 873697596434513921 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
    "# 869988702071779329 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
    "# 861769973181624320 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
    "# 842892208864923648 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
    "# 802247111496568832 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
    "# 775096608509886464 _ [{'code': 144, 'message': 'No status found with that ID.'}]\n",
    "# Rate limit reached. Sleeping for: 212\n",
    "# Rate limit reached. Sleeping for: 532\n",
    "# 1980.119999885559"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We repeat the same operation for the tweet_ids that we coudln't get and append the result to df_list\n",
    "ee_list = []\n",
    "for e in error_list:\n",
    "    try:\n",
    "        favorites = page['favorite_count']\n",
    "        retweets = page['retweet_count']\n",
    "        user_followers = page['user']['followers_count']\n",
    "        user_favourites = page['user']['favourites_count']\n",
    "        date_time = page['created_at']\n",
    "        \n",
    "        df_list.append({'tweet_id': int(tweet_id),\n",
    "                        'favorites': int(favorites),\n",
    "                        'retweets': int(retweets),\n",
    "                        'user_followers': int(user_followers),\n",
    "                        'user_favourites': int(user_favourites),\n",
    "                        'date_time': pd.to_datetime(date_time)})\n",
    "        \n",
    "    except Exception:\n",
    "        print(str(tweet_id)+ \" _ \" + str(e))\n",
    "        ee_list.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames from list of dictionaries\n",
    "json_tweets = pd.DataFrame(df_list, columns = ['tweet_id', 'favorites', 'retweets',\n",
    "                                               'user_followers', 'user_favourites', 'date_time'])\n",
    "\n",
    "# Save the dataFrame in file\n",
    "json_tweets.to_csv('tweet_json.txt', encoding = 'utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 6 columns):\n",
      "tweet_id           2356 non-null int64\n",
      "favorites          2356 non-null int64\n",
      "retweets           2356 non-null int64\n",
      "user_followers     2356 non-null int64\n",
      "user_favourites    2356 non-null int64\n",
      "date_time          2356 non-null object\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 110.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the outcome\n",
    "# Read the saved tweet_json.txt file into a dataframe\n",
    "json_tweets = pd.read_csv('tweet_json.txt', encoding = 'utf-8')\n",
    "json_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
